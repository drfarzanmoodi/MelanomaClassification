{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Z-yhpN6Q5KQH"
      },
      "outputs": [],
      "source": [
        "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# # For example, here's several helpful packages to load\n",
        "\n",
        "# import numpy as np # linear algebra\n",
        "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# # Input data files are available in the read-only \"../input/\" directory\n",
        "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "# import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWHKkr9x5PBz",
        "outputId": "1b4a653c-03da-44b8-cf6b-82bc4dcc0c88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeuZGNEq5KQN",
        "outputId": "7fc95bd7-7a78-4dd0-903f-e93f646b6736"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Requirement '/lib/wheels/tensorflow-2.9.1-cp38-cp38-linux_x86_64.whl' looks like a filename, but the file does not exist\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: tensorflow-2.9.1-cp38-cp38-linux_x86_64.whl is not a supported wheel on this platform.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "import os\n",
        "!pip install -q /lib/wheels/tensorflow-2.9.1-cp38-cp38-linux_x86_64.whl\n",
        "!pip install -q tensorflow-addons==0.18.0\n",
        "!pip install -q tensorflow-probability==0.17.0\n",
        "!pip install -q opencv-python-headless\n",
        "!pip install -q seaborn\n",
        "\n",
        "\n",
        "!pip install -qU wandb\n",
        "!pip install -qU scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IE8t2TjZ5KQO"
      },
      "outputs": [],
      "source": [
        "# CHANGED FOR TPU 1VM:\n",
        "# Apparently you may use different seed values at each stage\n",
        "seed_value= 0\n",
        "\n",
        "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "\n",
        "\n",
        "# For working on GPUs from \"TensorFlow Determinism\"\n",
        "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
        "\n",
        "\n",
        "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
        "import random\n",
        "#                   random.seed(seed_value)\n",
        "\n",
        "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
        "import numpy as np\n",
        "#                   np.random.seed(seed_value)\n",
        "\n",
        "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(seed_value)\n",
        "\n",
        "# for later versions:\n",
        "# tf.compat.v1.set_random_seed(seed_value)\n",
        "\n",
        "# 5. Configure a new global `tensorflow` session\n",
        "from keras import backend as K\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=4, inter_op_parallelism_threads=4)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "tf.compat.v1.keras.backend.set_session(sess)\n",
        "# /content/drive/MyDrive/QMISG_Prostate_Dataset&Codes/Prostate_Dataset/ProstateX Challenge/Preprocessed_Data/2D_MultiSeq_SingleSlice_Lesion/QISO/QISO_CropFixed_32px\n",
        "# Imports\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import glob\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "# Get the current date and time\n",
        "current_datetime = datetime.now().strftime('%Y-%m-%d %H:%M')  # Format: YYYY-MM-DD HH:MM\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob, os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from keras.optimizers import SGD, RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.layers import concatenate\n",
        "\n",
        "\n",
        "# Imports\n",
        "\n",
        "import keras\n",
        "# from keras.utils import np_utils\n",
        "keras.utils.set_random_seed(seed_value)\n",
        "from tensorflow.keras.layers import (\n",
        "  BatchNormalization, SeparableConv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense , Input\n",
        ")\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras import callbacks\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
        "#                   import seaborn as sns\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from keras import layers\n",
        "\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import tensorflow_datasets as tfds\n",
        "# import tensorflow_addons as tfa\n",
        "# import tensorflow_probability as tfp\n",
        "# Detect hardware, return appropriate distribution strategy\n",
        "# try:\n",
        "#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect(tpu=\"local\") # \"local\" for 1VM TPU\n",
        "#     strategy = tf.distribute.TPUStrategy(tpu)\n",
        "# except tf.errors.NotFoundError:\n",
        "#     strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "# print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufQj_VJF5KQP"
      },
      "outputs": [],
      "source": [
        "RUN_BY = \"Moodi\"\n",
        "COMMENT = \"Resnetcombined\"\n",
        "Fixed_CropSize = 64\n",
        "EPOCHS = 20\n",
        "BATCHSIZE = 32\n",
        "RESAMPLING = \"ISO_zNorm_v1\"\n",
        "RESIZE = True\n",
        "SMOTE_STATE = True\n",
        "height=Fixed_CropSize\n",
        "width=Fixed_CropSize\n",
        "channelss = [0, 1, 2, 3, 4]\n",
        "# channels = [2,3,4] #0:T2_1:ADC_2:BVAL_3:DWI_4:Ktrans\n",
        "num_channels= 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzOXH9so5KQQ"
      },
      "outputs": [],
      "source": [
        "# Define directory paths\n",
        "output_dir = f\"/kaggle/working/{RUN_BY}/Figures\"  # Modify the path as needed\n",
        "\n",
        "# Check if the directory exists, and if not, create it\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60vWJOjc5KQR"
      },
      "outputs": [],
      "source": [
        "# import requests\n",
        "\n",
        "# url = \"https://api.isic-archive.com/api/v2/collections/\"\n",
        "# headers = {\n",
        "#     \"accept\": \"application/json\",\n",
        "#     \"X-CSRFToken\": \"Kk1COEFP2gEFvnknSU4F4ZOyFlXhyTKHOZgpFPi1pFEnAH6IRFTLpXEA5gwL9U2Q\",\n",
        "# }\n",
        "\n",
        "# response = requests.get(url, headers=headers)\n",
        "\n",
        "# # You can then work with the response, e.g., check the status code or content.\n",
        "# print(response.status_code)\n",
        "# print(response.text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWMoyxLp5KQT"
      },
      "outputs": [],
      "source": [
        "# /kaggle/input/siim-isic-melanoma-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vppAo0c05KQU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoaQAJQ15KQU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "main_directory = '/kaggle/input/siim-isic-melanoma-classification/jpeg'\n",
        "image_directory = main_directory + '/train'\n",
        "\n",
        "# Load the CSV file\n",
        "csv_file = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/train.csv')\n",
        "\n",
        "# Define a function to find the image paths and labels\n",
        "def find_images_and_labels(csv_file, image_directory):\n",
        "    image_paths, labels = [], []\n",
        "    count = 0\n",
        "    for idx, row in csv_file.iterrows():\n",
        "        image_id = row['image_name']\n",
        "        label = row['target']\n",
        "        count+=1\n",
        "#         print(image_id, label)\n",
        "# /kaggle/input/siim-isic-melanoma-classification/jpeg/train/ISIC_0015719.jpg\n",
        "        # Search for image files in the specified directory\n",
        "        image_files = glob.glob(image_directory + f'/{image_id}.jpg')\n",
        "#         print(image_files)\n",
        "        # Add the found paths and labels to the lists\n",
        "        if len(image_files) > 0:\n",
        "            image_paths.extend(image_files)\n",
        "            labels.extend([label] * len(image_files))\n",
        "\n",
        "#         if count == 500:\n",
        "#             break\n",
        "    return image_paths, labels\n",
        "\n",
        "# Find image paths and labels for the train set\n",
        "X_train_path, Y_train = find_images_and_labels(csv_file, image_directory)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZjG0quR5KQV"
      },
      "outputs": [],
      "source": [
        "# csv_file[\"image_name\"].loc(\"ISIC_2637011\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mD0vxDs5KQV"
      },
      "outputs": [],
      "source": [
        "# X_train_path[0], X_train_path[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmRFRSI-5KQW"
      },
      "outputs": [],
      "source": [
        "# for path in X_train_path:\n",
        "#     csv_file.loc[path[-16:-4]].add[\"x_col\"]=path\n",
        "#     csv_file['image_name'] = csv_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNBDkVZC5KQW"
      },
      "outputs": [],
      "source": [
        "# csv_file_test = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/test.csv')\n",
        "# image_directory_test = main_directory + '/test'\n",
        "# X_test, Y_test = find_images_and_labels(csv_file_test, image_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4foEzWCx5KQW"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# import numpy as np\n",
        "# import glob\n",
        "\n",
        "# def load_and_preprocess_images(image_paths, target_size=(224, 224)):\n",
        "#     images = []\n",
        "#     count = 0\n",
        "#     for image_path in image_paths:\n",
        "#         # Load the image using TensorFlow's load_img\n",
        "#         image = tf.keras.utils.load_img(image_path, target_size=target_size)\n",
        "#         # Convert the loaded image to a NumPy array\n",
        "#         input_arr = tf.keras.utils.img_to_array(image)\n",
        "#         # Normalize pixel values to the range [0, 1]\n",
        "#         input_arr = input_arr / 255.0\n",
        "#         images.append(input_arr)\n",
        "#         count+=1\n",
        "#         if count%2000==0:\n",
        "#             print(count)\n",
        "#     return np.array(images)\n",
        "\n",
        "# images = load_and_preprocess_images(X_train_path)\n",
        "\n",
        "\n",
        "\n",
        "# # images = load_and_preprocess_images(X_train_path[:50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HosK62hR5KQW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import glob\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def load_and_preprocess_image(image_path, target_size=(224, 224)):\n",
        "    # Load the image using TensorFlow's load_img\n",
        "    image = tf.keras.utils.load_img(image_path, target_size=target_size)\n",
        "    # Convert the loaded image to a NumPy array\n",
        "    input_arr = tf.keras.utils.img_to_array(image)\n",
        "    # Normalize pixel values to the range [0, 1]\n",
        "    input_arr = input_arr / 255.0\n",
        "    return input_arr\n",
        "\n",
        "def load_and_preprocess_images(image_paths, target_size=(224, 224), num_threads=4):\n",
        "    images = []\n",
        "\n",
        "    # Create a ThreadPoolExecutor with the specified number of threads\n",
        "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "        count = 0\n",
        "        for image in executor.map(load_and_preprocess_image, image_paths):\n",
        "            images.append(image)\n",
        "            count += 1\n",
        "            if count % 2000 == 0:\n",
        "                print(\"Loaded\", count, \"images\")\n",
        "\n",
        "    return np.array(images)\n",
        "\n",
        "# List of image file paths\n",
        "# X_train_path = glob.glob(\"/path/to/your/images/*.jpg\")\n",
        "\n",
        "# Example usage:\n",
        "images = load_and_preprocess_images(X_train_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JMD9jO15KQX"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# import numpy as np\n",
        "# import glob\n",
        "# from concurrent.futures import ThreadPoolExecutor\n",
        "# import gc  # Import the garbage collection module\n",
        "\n",
        "# def load_and_preprocess_image(image_path, target_size=(224, 224)):\n",
        "#     # Load the image using TensorFlow's load_img\n",
        "#     image = tf.keras.utils.load_img(image_path, target_size=target_size)\n",
        "#     # Convert the loaded image to a NumPy array\n",
        "#     input_arr = tf.keras.utils.img_to_array(image)\n",
        "#     # Normalize pixel values to the range [0, 1]\n",
        "#     input_arr = input_arr / 255.0\n",
        "#     return input_arr\n",
        "\n",
        "# def load_and_preprocess_images(image_paths, target_size=(224, 224), num_threads=4, batch_size=2000):\n",
        "#     images = []\n",
        "\n",
        "#     # Create a ThreadPoolExecutor with the specified number of threads\n",
        "#     with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "#         count = 0\n",
        "#         for image in executor.map(load_and_preprocess_image, image_paths):\n",
        "#             images.append(image)\n",
        "#             count += 1\n",
        "#             if count % batch_size == 0:\n",
        "#                 print(\"Loaded\", count, \"images\")\n",
        "#                 # Explicitly release memory\n",
        "#                 del images\n",
        "#                 images = []\n",
        "#                 gc.collect()\n",
        "\n",
        "#     return np.array(images)\n",
        "\n",
        "# # List of image file paths\n",
        "# # X_train_path = glob.glob(\"/path/to/your/images/*.jpg\")\n",
        "\n",
        "# # Example usage:\n",
        "# images = load_and_preprocess_images(X_train_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-PgyKjd5KQX"
      },
      "outputs": [],
      "source": [
        "len(images),len(Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gf8Ep6Ju5KQX"
      },
      "outputs": [],
      "source": [
        "# Y_train = Y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaoEWuse5KQX"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convert the lists to numpy arrays\n",
        "# X_train = np.array(X_train)\n",
        "# Y_train = np.array(Y_train[])\n",
        "\n",
        "# # Check the shape\n",
        "# X_train.shape, Y_train.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iu13JH15KQX"
      },
      "outputs": [],
      "source": [
        "# Assuming you have Y_train_split, Y_valid_split, and Y_test_split as your labels\n",
        "\n",
        "# Define a dictionary to map benign and malignant to 0 and 1\n",
        "# label_mapping = {\"benign\": 0, \"malignant\": 1}\n",
        "\n",
        "# # Update labels for the training set\n",
        "# Y_train = [label_mapping[label] for label in Y_train]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvPt3ooP5KQY"
      },
      "outputs": [],
      "source": [
        "# Convert the list Y_train to a NumPy array\n",
        "Y_train = np.array(Y_train)\n",
        "Y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSh9d6ZP5KQY"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "\n",
        "# # Assuming you have X_train and Y_train as your training data and labels\n",
        "\n",
        "# # Define the ratios\n",
        "# train_ratio = 0.8\n",
        "# valid_ratio = 0.1\n",
        "# test_ratio = 0.1\n",
        "\n",
        "# # Calculate the number of samples for each set\n",
        "# num_samples = len(images)\n",
        "# num_train = int(num_samples * train_ratio)\n",
        "# num_valid = int(num_samples * valid_ratio)\n",
        "\n",
        "# # Shuffle the data\n",
        "# indices = np.random.permutation(num_samples)\n",
        "# X_train_shuffled = images[indices]\n",
        "# Y_train_shuffled = Y_train[indices]\n",
        "\n",
        "# # Split the data\n",
        "# X_train_split = X_train_shuffled[:num_train]\n",
        "# Y_train_split = Y_train_shuffled[:num_train]\n",
        "\n",
        "# X_valid_split = X_train_shuffled[num_train:num_train + num_valid]\n",
        "# Y_valid_split = Y_train_shuffled[num_train:num_train + num_valid]\n",
        "\n",
        "# X_test_split = X_train_shuffled[num_train + num_valid:]\n",
        "# Y_test_split = Y_train_shuffled[num_train + num_valid:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3RvoZW29SK0"
      },
      "outputs": [],
      "source": [
        "!ls /content/drive/MyDrive/ISIC/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFN3CDHF5qI9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the directory and parameters\n",
        "directory = '/content/drive/MyDrive/ISIC/'\n",
        "batch_size = 32\n",
        "image_size = (224, 224)\n",
        "\n",
        "# Get the class names from the directory\n",
        "class_names = sorted(os.listdir(directory))\n",
        "\n",
        "# Load the dataset using tf.keras.preprocessing.image_dataset_from_directory\n",
        "ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory,\n",
        "    labels='inferred',\n",
        "    label_mode='int',  # Change this to 'binary' if you specifically want binary labels\n",
        "    batch_size=batch_size,\n",
        "    image_size=image_size,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Take the first 500 files\n",
        "ds_first_500 = ds.take(50 // batch_size)\n",
        "\n",
        "# Extract file paths and labels\n",
        "file_paths = []\n",
        "labels = []\n",
        "for images, labels_batch in ds_first_500:\n",
        "    file_paths.extend(images.numpy())\n",
        "    labels.extend(labels_batch.numpy())\n",
        "\n",
        "# Split the data into train, validation, and test sets with an 80-10-10 ratio\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "    file_paths, labels, test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "valid_paths, test_paths, valid_labels, test_labels = train_test_split(\n",
        "    test_paths, test_labels, test_size=0.5, random_state=42, stratify=test_labels\n",
        ")\n",
        "\n",
        "# Create TensorFlow Datasets for train, validation, and test sets\n",
        "ds_train = tf.data.Dataset.from_tensor_slices((train_paths, train_labels)).batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "ds_valid = tf.data.Dataset.from_tensor_slices((valid_paths, valid_labels)).batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "ds_test = tf.data.Dataset.from_tensor_slices((test_paths, test_labels)).batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# Print the number of examples in each set\n",
        "print(\"Number of examples in training set:\", len(train_paths))\n",
        "print(\"Number of examples in validation set:\", len(valid_paths))\n",
        "print(\"Number of examples in test set:\", len(test_paths))"
      ],
      "metadata": {
        "id": "yTIGOiwrl_-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_train_validation = 42 # Must be same for train_ds and val_ds\n",
        "shuffle_value = True\n",
        "validation_split = 0.3\n",
        "# Define the directory and parameters\n",
        "directory = '/content/drive/MyDrive/ISIC/'\n",
        "batch_size = 32\n",
        "image_size = (224, 224)\n",
        "ds_train = tf.keras.utils.image_dataset_from_directory(\n",
        "directory =directory,\n",
        "image_size = (224, 224),\n",
        "validation_split = validation_split,\n",
        "subset = \"training\",\n",
        "seed = seed_train_validation,\n",
        "color_mode = 'rgb',\n",
        "shuffle = shuffle_value)\n",
        "\n",
        "ds_val = tf.keras.utils.image_dataset_from_directory(\n",
        "directory =directory,\n",
        "image_size = (224, 224),\n",
        "validation_split = validation_split,\n",
        "subset = \"validation\",\n",
        "seed = seed_train_validation,\n",
        "color_mode = 'rgb',\n",
        "shuffle = False\n",
        ")\n",
        "val_batches = tf.data.experimental.cardinality(ds_val)\n",
        "ds_test = ds_val.take((2*val_batches) // 3)\n",
        "ds_valid = ds_val.skip((2*val_batches) // 3)"
      ],
      "metadata": {
        "id": "I7dQubkQwACC",
        "outputId": "9bf08f5b-f404-46fe-9c6b-7be649ff0aa0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 39015 files belonging to 2 classes.\n",
            "Using 27311 files for training.\n",
            "Found 39015 files belonging to 2 classes.\n",
            "Using 11704 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(ds_val)*32, len(ds_test)*32"
      ],
      "metadata": {
        "id": "RfKoUz51wog7",
        "outputId": "a6dcb7cc-6644-431f-d120-98c8ff30a03c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11712, 7808)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FCJEs5L5KQZ"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # Assuming you have 'images' and 'Y_train' as your training data and labels\n",
        "# # Let's assume that 'Y_train' contains binary class labels (0 and 1)\n",
        "\n",
        "# # Define the ratios\n",
        "# train_ratio = 0.8\n",
        "# valid_ratio = 0.1\n",
        "# test_ratio = 0.1\n",
        "\n",
        "# # Find the indices for class 0 and class 1 samples\n",
        "# class_0_indices = np.where(Y_train == 0)[0]\n",
        "# class_1_indices = np.where(Y_train == 1)[0]\n",
        "\n",
        "# # Split the data for class 0 into train, validation, and test sets\n",
        "# class_0_train_indices, class_0_remaining_indices = train_test_split(class_0_indices, test_size=1 - train_ratio, random_state=42)\n",
        "# class_0_valid_indices, class_0_test_indices = train_test_split(class_0_remaining_indices, test_size=test_ratio / (valid_ratio + test_ratio), random_state=42)\n",
        "\n",
        "# # Split the data for class 1 into train, validation, and test sets\n",
        "# class_1_train_indices, class_1_remaining_indices = train_test_split(class_1_indices, test_size=1 - train_ratio, random_state=42)\n",
        "# class_1_valid_indices, class_1_test_indices = train_test_split(class_1_remaining_indices, test_size=test_ratio / (valid_ratio + test_ratio), random_state=42)\n",
        "\n",
        "# # Combine the class 0 and class 1 indices for each set\n",
        "# train_indices = np.concatenate([class_0_train_indices, class_1_train_indices])\n",
        "# valid_indices = np.concatenate([class_0_valid_indices, class_1_valid_indices])\n",
        "# test_indices = np.concatenate([class_0_test_indices, class_1_test_indices])\n",
        "\n",
        "# # Split your data into train, validation, and test sets using the calculated indices\n",
        "# X_train, X_valid, X_test = images[train_indices], images[valid_indices], images[test_indices]\n",
        "# Y_train, Y_valid, Y_test = Y_train[train_indices], Y_train[valid_indices], Y_train[test_indices]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odqzmw745KQZ"
      },
      "outputs": [],
      "source": [
        "# len(X_train), len(X_valid), len(X_test),Y_train.shape, Y_valid.shape, Y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tKzWg_XE5KQZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# # Define data generators\n",
        "# datagen = ImageDataGenerator()  # You can add more data augmentation parameters here\n",
        "\n",
        "# # Train Dataloader\n",
        "# train_data_generator = datagen.flow(X_train_split, Y_train_split, batch_size=BATCHSIZE, shuffle=True)\n",
        "\n",
        "# # Validation Dataloader\n",
        "# valid_data_generator = datagen.flow(X_valid_split, Y_valid_split, batch_size=BATCHSIZE, shuffle=False)\n",
        "\n",
        "# # Test Dataloader\n",
        "# test_data_generator = datagen.flow(X_test_split, Y_test_split, batch_size=BATCHSIZE, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOV_-3ba5KQZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming ds_train contains images and labels\n",
        "num_images_to_plot = 5\n",
        "\n",
        "for images, labels in ds_train.take(num_images_to_plot):\n",
        "    for i in range(len(images)):\n",
        "        plt.figure(figsize=(4, 4))\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(f'Label: {labels[i].numpy()}')\n",
        "        plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycNSBG9f5KQZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oizTPaZ55KQZ",
        "outputId": "ed7adc2c-5d27-45ef-fd27-6a2e9ac6a15e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 00001: CosineAnnealingScheduler setting learning rate to 0.01.\n",
            "854/854 [==============================] - ETA: 0s - loss: 0.3890 - binary_accuracy: 0.8232 - auc: 0.8155 \n",
            "Epoch 1: val_binary_accuracy improved from -inf to 0.49179, saving model to /content/mydrive/melanomaweights.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r854/854 [==============================] - 6758s 8s/step - loss: 0.3890 - binary_accuracy: 0.8232 - auc: 0.8155 - val_loss: 0.8744 - val_binary_accuracy: 0.4918 - val_auc: 0.0000e+00 - lr: 0.0100\n"
          ]
        }
      ],
      "source": [
        "model_kwargs = {\"image_size\":224,\"input_channels\": 3, \"filters\":256, \"depth\":4, \"kernel_size\":5, \"patch_size\":32, \"num_classes\":1}\n",
        "\n",
        "def activation_block(x):\n",
        "  x = layers.Activation(\"gelu\")(x)\n",
        "  return layers.BatchNormalization()(x)\n",
        "\n",
        "\n",
        "def conv_stem(x, filters: int, patch_size: int):\n",
        "  x = layers.Conv2D(filters, kernel_size=patch_size, strides=patch_size)(x)\n",
        "  return activation_block(x)\n",
        "\n",
        "\n",
        "def conv_mixer_block(x, filters: int, kernel_size: int):\n",
        "  # Depthwise convolution.\n",
        "  x0 = x\n",
        "  x = layers.DepthwiseConv2D(kernel_size=kernel_size, padding=\"same\")(x)\n",
        "  x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "\n",
        "  # Pointwise convolution.\n",
        "  x = layers.Conv2D(filters, kernel_size=1)(x)\n",
        "  x = activation_block(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "\n",
        "def get_conv_mixer_256_8(\n",
        "  image_size=224, input_channels= 3, filters=256, depth=4, kernel_size=5, patch_size=32, num_classes=1\n",
        "):\n",
        "  \"\"\"ConvMixer-256/8: https://openreview.net/pdf?id=TVHS5Y4dNvM.\n",
        "  The hyperparameter values are taken from the paper.\n",
        "  \"\"\"\n",
        "  inputs = keras.Input((image_size, image_size, input_channels))\n",
        "  # x = layers.Rescaling(scale=1.0 / 255)(inputs)\n",
        "\n",
        "  # Extract patch embeddings.\n",
        "  x = conv_stem(inputs, filters, patch_size)\n",
        "\n",
        "  # ConvMixer blocks.\n",
        "  for _ in range(depth):\n",
        "      x = conv_mixer_block(x, filters, kernel_size)\n",
        "\n",
        "  # Classification block.\n",
        "  x = layers.GlobalAvgPool2D()(x)\n",
        "  outputs = layers.Dense(num_classes, activation=\"sigmoid\")(x)\n",
        "\n",
        "  return keras.Model(inputs, outputs)\n",
        "\n",
        "custom_vgg_model = get_conv_mixer_256_8(**model_kwargs)\n",
        "checkpoint_filepath = f'/content/mydrive/melanomaweights.h5'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "  filepath=checkpoint_filepath,\n",
        "  save_weights_only=False,\n",
        "  verbose=1,\n",
        "  monitor='val_binary_accuracy',\n",
        "  mode='max',\n",
        "  save_best_only=True)\n",
        "import math\n",
        "from keras.callbacks import Callback\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "class CosineAnnealingScheduler(Callback):\n",
        "  \"\"\"Cosine annealing scheduler.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, T_max, eta_max, eta_min=0, verbose=1):\n",
        "      super(CosineAnnealingScheduler, self).__init__()\n",
        "      self.T_max = T_max\n",
        "      self.eta_max = eta_max\n",
        "      self.eta_min = eta_min\n",
        "      self.verbose = verbose\n",
        "\n",
        "  def on_epoch_begin(self, epoch, logs=None):\n",
        "      if not hasattr(self.model.optimizer, 'lr'):\n",
        "          raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
        "      lr = self.eta_min + (self.eta_max - self.eta_min) * (1 + math.cos(math.pi * epoch / self.T_max)) / 2\n",
        "      K.set_value(self.model.optimizer.lr, lr)\n",
        "      if self.verbose > 0:\n",
        "          print('\\nEpoch %05d: CosineAnnealingScheduler setting learning '\n",
        "                'rate to %s.' % (epoch + 1, lr))\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "      logs = logs or {}\n",
        "      logs['lr'] = K.get_value(self.model.optimizer.lr)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# lr_decayed_fn = (\n",
        "#   tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
        "#       initial_learning_rate=1e-4,\n",
        "#       first_decay_steps = 1000))\n",
        "# sgd=SGD(learning_rate=1e-3,decay=1e-6,momentum=0.9,nesterov=True)\n",
        "\n",
        "sgd=tf.keras.optimizers.experimental.AdamW(\n",
        "  learning_rate=0.001,\n",
        "  weight_decay=0.004,\n",
        "  beta_1=0.9,\n",
        "  beta_2=0.999,\n",
        "  epsilon=1e-07,\n",
        "  amsgrad=False,\n",
        "  clipnorm=None,\n",
        "  clipvalue=None,\n",
        "  global_clipnorm=None,\n",
        "  use_ema=False,\n",
        "  ema_momentum=0.99,\n",
        "  ema_overwrite_frequency=None,\n",
        "  jit_compile=True,\n",
        "  name=\"AdamW\",\n",
        "\n",
        ")\n",
        "CA_Scheduler= CosineAnnealingScheduler(T_max=len(ds_train), eta_max=1e-2, eta_min=1e-5)\n",
        "#                   with tpu_strategy.scope():\n",
        "\n",
        "#                   from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "#                   from tensorflow.keras.models import Model\n",
        "# #                   with tpu_strategy.scope():\n",
        "#                 # Create the ResNet50 model\n",
        "#                   pre_trained_model = ResNet50(include_top=False, weights=None, pooling='avg')\n",
        "\n",
        "#                     # Load the weights from the file\n",
        "#                     # weights_path = '/content/drive/MyDrive/QMISG_Prostate_Dataset&Codes/Prostate_Dataset/ProstateX Challenge/medicalimagenet/RadImageNet-ResNet50_notop.h5'\n",
        "#                     # pre_trained_model.load_weights(weights_path)\n",
        "\n",
        "#                     # Add a fully connected layer with sigmoid activation for a single class\n",
        "#                   num_classes = 1\n",
        "#                   x = pre_trained_model.output\n",
        "#                   x = Dense(256, activation='relu')(x)\n",
        "#                   predictions = Dense(num_classes, activation='sigmoid')(x)\n",
        "#                   from tensorflow.keras import layers\n",
        "#                   from tensorflow import keras\n",
        "\n",
        "#                   def activation_block(x):\n",
        "#                         x = layers.Activation(\"gelu\")(x)\n",
        "#                         return layers.BatchNormalization()(x)\n",
        "\n",
        "#                   def residual_block(x, filters: int, kernel_size: int):\n",
        "#                         # Convolution path.\n",
        "#                         shortcut = layers.Conv2D(filters, kernel_size=1, strides=1)(x)\n",
        "\n",
        "#                         # Residual path.\n",
        "#                         x = layers.Conv2D(filters, kernel_size=kernel_size, strides=1, padding=\"same\")(x)\n",
        "#                         x = activation_block(x)\n",
        "#                         x = layers.Conv2D(filters, kernel_size=kernel_size, strides=1, padding=\"same\")(x)\n",
        "#                         x = layers.BatchNormalization()(x)\n",
        "\n",
        "#                         # Merge paths.\n",
        "#                         x = layers.Add()([shortcut, x])\n",
        "\n",
        "#                         return x\n",
        "\n",
        "#                   def conv_mixer_block(x, filters: int, kernel_size: int):\n",
        "#                         # Depthwise convolution.\n",
        "#                         x0 = x\n",
        "#                         x = layers.DepthwiseConv2D(kernel_size=kernel_size, padding=\"same\")(x)\n",
        "#                         x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "\n",
        "#                         # Pointwise convolution.\n",
        "#                         x = layers.Conv2D(filters, kernel_size=1)(x)\n",
        "#                         x = activation_block(x)\n",
        "\n",
        "#                         return x\n",
        "\n",
        "#                   def get_conv_mixer_256_8(\n",
        "#                         image_size=224, input_channels=3, filters=256, depth=8, kernel_size=5, patch_size=16, num_classes=1\n",
        "#                     ):\n",
        "#                         inputs = keras.Input((image_size, image_size, input_channels))\n",
        "#                         print(inputs.shape)\n",
        "\n",
        "#                         # First ResNet block\n",
        "#                         x = layers.Conv2D(filters, kernel_size=7, strides=2)(inputs)\n",
        "#                         x = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
        "\n",
        "#                         # ConvMixer blocks.\n",
        "#                         for _ in range(depth):\n",
        "#                             x = conv_mixer_block(x, filters, kernel_size)\n",
        "\n",
        "#                         # Classification block.\n",
        "#                         x = layers.GlobalAvgPool2D()(x)\n",
        "#                         outputs = layers.Dense(num_classes, activation=\"sigmoid\")(x)\n",
        "\n",
        "#                         return keras.Model(inputs, outputs)\n",
        "\n",
        "#                   model_kwargs = {\n",
        "#                         \"image_size\": 224,\n",
        "#                         \"input_channels\": 3,\n",
        "#                         \"filters\": 256,\n",
        "#                         \"depth\": 4,\n",
        "#                         \"kernel_size\": 5,\n",
        "#                         \"patch_size\": 32,\n",
        "#                         \"num_classes\": 1,\n",
        "#                     }\n",
        "#                   from tensorflow.keras import layers, Model\n",
        "\n",
        "#                     # Define the ResNet block with skip connection\n",
        "#                   def resnet_block(x, filters, kernel_size):\n",
        "#                         shortcut = x\n",
        "#                         x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
        "#                         x = layers.BatchNormalization()(x)\n",
        "#                         x = layers.Activation('relu')(x)\n",
        "#                         x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
        "#                         x = layers.BatchNormalization()(x)\n",
        "#                         x = layers.Add()([x, shortcut])  # Skip connection\n",
        "#                         x = layers.Activation('relu')(x)\n",
        "#                         return x\n",
        "\n",
        "#                     # Define the ConvMixer block without skip connection\n",
        "#                   def conv_mixer_block(x, filters, kernel_size):\n",
        "#                         # Depthwise convolution.\n",
        "#                         x0 = x\n",
        "#                         x = layers.DepthwiseConv2D(kernel_size=kernel_size, padding=\"same\")(x)\n",
        "#                         x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "\n",
        "#                         # Pointwise convolution.\n",
        "#                         x = layers.Conv2D(filters, kernel_size=1)(x)\n",
        "#                         x = activation_block(x)\n",
        "\n",
        "#                         return x\n",
        "\n",
        "#                     # Function to build the ConvMixer model with the ResNet-style block\n",
        "#                   def get_conv_mixer_with_resnet_block(\n",
        "#                         image_size=224, input_channels=3, filters=256, depth=8, kernel_size=5, patch_size=16, num_classes=1\n",
        "#                     ):\n",
        "#                         inputs = keras.Input(shape=(image_size, image_size, input_channels))\n",
        "#                         x = layers.Conv2D(filters, patch_size, patch_size, padding='same')(inputs)\n",
        "\n",
        "#                         # Add the ResNet-style block\n",
        "#                         x = resnet_block(x, filters, 3)  # You can customize the kernel size as needed\n",
        "\n",
        "#                         # ConvMixer blocks.\n",
        "#                         for _ in range(depth):\n",
        "#                             x = conv_mixer_block(x, filters, kernel_size)\n",
        "\n",
        "#                         # Classification block.\n",
        "#                         x = layers.GlobalAveragePooling2D()(x)\n",
        "#                         outputs = layers.Dense(num_classes, activation=\"sigmoid\")(x)\n",
        "\n",
        "#                         model = Model(inputs, outputs)\n",
        "#                         return model\n",
        "#                   import tensorflow as tf\n",
        "#                   from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "#                             # Define the activation block\n",
        "#                   def activation_block(x):\n",
        "#                                 x = tf.keras.layers.Activation(\"gelu\")(x)\n",
        "#                                 x = tf.keras.layers.BatchNormalization()(x)\n",
        "#                                 return x\n",
        "\n",
        "#                             # Define the ConvMixer architecture with specified parameters\n",
        "#                   def get_conv_mixer(filters=256, depth=8, kernel_size=5, patch_size=16, num_classes=1):\n",
        "#                                 # Add ResNet-50 as the first layer\n",
        "#                                 resnet_model = ResNet50(include_top=False, weights=None, input_shape=(224, 224, 3))\n",
        "#                                 resnet_output = resnet_model.output\n",
        "\n",
        "#                                 # Define the conv_stem function\n",
        "#                                 def conv_stem(x, filters: int, patch_size: int):\n",
        "#                                     x = tf.keras.layers.Conv2D(filters, kernel_size=patch_size, strides=patch_size)(x)\n",
        "#                                     x = activation_block(x)\n",
        "#                                     return x\n",
        "\n",
        "#                                 # Extract patch embeddings.\n",
        "#                                 x = conv_stem(resnet_output, filters, patch_size)\n",
        "\n",
        "#                                 # ConvMixer blocks.\n",
        "#                                 for _ in range(depth):\n",
        "#                                     x0 = x\n",
        "#                                     x = tf.keras.layers.DepthwiseConv2D(kernel_size=kernel_size, padding=\"same\")(x)\n",
        "#                                     x = tf.keras.layers.Add()([activation_block(x), x0])\n",
        "#                                     x = tf.keras.layers.Conv2D(filters, kernel_size=1)(x)\n",
        "#                                     x = activation_block(x)\n",
        "\n",
        "#                                 # Classification block.\n",
        "#                                 x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "#                                 outputs = tf.keras.layers.Dense(num_classes, activation=\"sigmoid\")(x)\n",
        "\n",
        "#                                 # Create a new model that includes ResNet-50 and the ConvMixer architecture\n",
        "#                                 combined_model = tf.keras.Model(inputs=resnet_model.input, outputs=outputs)\n",
        "\n",
        "#                                 return combined_model\n",
        "\n",
        "#                             # Define the parameters for the ConvMixer\n",
        "#                   model_kwargs = {\"filters\": 256, \"depth\": 4, \"kernel_size\": 5, \"patch_size\": 32, \"num_classes\": 1}\n",
        "\n",
        "#                             # Create the ConvMixer model with the specified parameters\n",
        "#                   custom_vgg_model = get_conv_mixer(**model_kwargs)\n",
        "\n",
        "        # Now you can use 'custom_conv_mixer_model' for your task\n",
        "\n",
        "# Example usage\n",
        "#                   model_kwargs = {\n",
        "#                         \"image_size\": 224,\n",
        "#                         \"input_channels\": 3,\n",
        "#                         \"filters\": 256,\n",
        "#                         \"depth\": 4,\n",
        "#                         \"kernel_size\": 5,\n",
        "#                         \"patch_size\": 32,\n",
        "#                         \"num_classes\": 1,\n",
        "#                     }\n",
        "\n",
        "#                   custom_vgg_model = get_conv_mixer_with_resnet_block(**model_kwargs)\n",
        "\n",
        "\n",
        "#                   custom_vgg_model = get_conv_mixer_256_8(**model_kwargs)\n",
        "\n",
        "#                   custom_vgg_model = Model(inputs=pre_trained_model.input, outputs=predictions)\n",
        "\n",
        "custom_vgg_model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False, label_smoothing=0),\n",
        "        optimizer=sgd,\n",
        "        metrics=[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.AUC(name='auc')])\n",
        "# **Training**\n",
        "# history = custom_vgg_model.fit([X_Train_Norm, Train_zone],Y_Train, epochs=60, batch_size=16,\n",
        "#                                validation_data=([X_Valid_Norm, Valid_zone], Y_Valid))\n",
        "# history = custom_vgg_model.fit(datagen.flow(X_Train_Norm,Y_Train, batch_size=64),\n",
        "#                                validation_data=(X_Valid_Norm, Y_Valid), class_weight=class_weight, callbacks=[ model_checkpoint_callback,CA_Scheduler], epochs=300)\n",
        "\n",
        "# # performing data argumentation by training image generator\n",
        "# dataAugmentaion = ImageDataGenerator(rotation_range = 60, zoom_range = 0.1,\n",
        "# fill_mode = \"nearest\", shear_range = 0.20, horizontal_flip = True, vertical_flip=True,\n",
        "# width_shift_range = 0.1, height_shift_range = 0.1)\n",
        "\n",
        "\n",
        "# # training the model\n",
        "# history = custom_vgg_model.fit(dataAugmentaion.flow(X_Train_Norm,Y_Train, batch_size=64),\n",
        "#  validation_data=(X_Valid_Norm, Y_Valid), class_weight=class_weight,\n",
        "#    epochs=400, callbacks=[ model_checkpoint_callback,CA_Scheduler])\n",
        "# Calculate the mean and std values from your dataset\n",
        "#                   mean=[0.485, 0.456, 0.406]\n",
        "#                   std=[0.229, 0.224, 0.225]  # RGB mean values for ImageNet dataset\n",
        "#                   # Standard deviation values for ImageNet dataset\n",
        "\n",
        "#                   # Preprocess input images using the calculated mean and std\n",
        "#                   def preprocess_with_mean_std(x):\n",
        "#                       x[..., 0] -= mean[0]\n",
        "#                       x[..., 1] -= mean[1]\n",
        "#                       x[..., 2] -= mean[2]\n",
        "#                       x[..., 0] /= std[0]\n",
        "#                       x[..., 1] /= std[1]\n",
        "#                       x[..., 2] /= std[2]\n",
        "#                       return x\n",
        "# Define the augmentation settings\n",
        "augmentation_settings = {\n",
        "  \"rotation_range\": 10,\n",
        "  \"width_shift_range\": 0.25,\n",
        "  \"height_shift_range\": 0.25,\n",
        "  \"brightness_range\": None,\n",
        "  \"shear_range\": 0.25,\n",
        "  \"zoom_range\": 0.4,\n",
        "  \"channel_shift_range\": 0,\n",
        "  \"horizontal_flip\": True,\n",
        "  \"vertical_flip\": True,\n",
        "  \"fill_mode\": 'constant',  # Set the fill mode to \"constant\"\n",
        "  \"cval\": 0.0  # Set the constant value to 0.0 for filling blank\n",
        "}\n",
        "\n",
        "dataAugmentaion = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "**augmentation_settings)\n",
        "\n",
        "# dataAugmentaion_VT = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "#     preprocessing_function=preprocess_with_mean_std)\n",
        "\n",
        "# training the model\n",
        "history = custom_vgg_model.fit(ds_train,\n",
        "validation_data=(ds_valid),\n",
        "epochs=1, callbacks=[ model_checkpoint_callback,CA_Scheduler], shuffle=True)\n",
        "\n",
        "\n",
        "# training the model\n",
        "# history = custom_vgg_model.fit(\n",
        "#     dataAugmentaion.flow(X_Train_Norm, Y_Train, batch_size=32),\n",
        "#     validation_data=dataAugmentaion_VT.flow(X_Valid_Norm, Y_Valid),\n",
        "#     epochs=300, callbacks=[model_checkpoint_callback, CA_Scheduler], shuffle=True\n",
        "  # )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjIIt-7h5KQa"
      },
      "outputs": [],
      "source": [
        "custom_vgg_model.load_weights(checkpoint_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5asTN6OQ5KQb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# **Plots**\n",
        "max_valAUC = max(history.history['val_auc'])\n",
        "\n",
        "acc = history.history['binary_accuracy']\n",
        "val_acc = history.history['val_binary_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_ax = range(1,len(val_loss)+1)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(epochs_ax, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_ax, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(epochs_ax, loss, label='Training Loss')\n",
        "plt.plot(epochs_ax, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim([0,2.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.savefig(f\"/kaggle/working/{RUN_BY}/Figures/Loss_{current_datetime}\")\n",
        "plt.show()\n",
        "\n",
        "# **Prediction after Warming up**\n",
        "\n",
        "\n",
        "# Get predictions on augmented validation data\n",
        "# prediction_Warmup = custom_vgg_model.predict(dataAugmentaion_VT.flow(X_Test_Norm, shuffle=False))\n",
        "\n",
        "\n",
        "# # prediction_Warmup = custom_vgg_model.predict([X_Test_Norm, Test_zone]).round()\n",
        "prediction_Warmup = custom_vgg_model.predict(X_test)\n",
        "\n",
        "prediction_Warmup.shape\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "# Assuming Y_Test and prediction_Warmup contain the true labels and model predictions, respectively.\n",
        "\n",
        "# Compute ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(Y_test, prediction_Warmup)\n",
        "\n",
        "# Calculate Youden's J statistic for each threshold\n",
        "j_stat = tpr + (1 - fpr) - 1\n",
        "\n",
        "# Find the threshold that maximizes Youden's J statistic\n",
        "best_threshold = thresholds[np.argmax(j_stat)]\n",
        "\n",
        "# Calculate the corresponding true positive rate (sensitivity) and false positive rate (1 - specificity)\n",
        "best_tpr = tpr[np.argmax(j_stat)]\n",
        "best_fpr = fpr[np.argmax(j_stat)]\n",
        "\n",
        "# Calculate the AUC score for reference\n",
        "auc_score = roc_auc_score(Y_test, prediction_Warmup)\n",
        "\n",
        "# Plot the ROC curve with the best threshold\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc_score:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "plt.scatter(best_fpr, best_tpr, c='red', label=f'Best Threshold = {best_threshold:.2f}')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend()\n",
        "plt.savefig(f\"/kaggle/working/{RUN_BY}/Figures/AUC_{current_datetime}\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Best Threshold:\", best_threshold)\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Convert predicted probabilities to binary predictions using the best threshold\n",
        "binary_predictions = (prediction_Warmup >= best_threshold).astype(int)\n",
        "\n",
        "# Convert true labels to binary format\n",
        "y_true = Y_test\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_true, binary_predictions)\n",
        "\n",
        "# Calculate sensitivity (true positive rate)\n",
        "sensitivity = recall_score(y_true, binary_predictions)\n",
        "\n",
        "# Calculate specificity (true negative rate)\n",
        "specificity = recall_score(y_true, binary_predictions, pos_label=0)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_true, binary_predictions)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_true, binary_predictions)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_true, binary_predictions)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "print(\"Sensitivity (True Positive Rate):\", sensitivity)\n",
        "print(\"Specificity (True Negative Rate):\", specificity)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "import csv\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Define the file path for the log data\n",
        "log_file_path = f'/kaggle/working/{RUN_BY}/PROSTATEX_log_data.csv'\n",
        "\n",
        "# Check if the log file exists\n",
        "if os.path.exists(log_file_path):\n",
        "  # If the file exists, try to load the existing log data\n",
        "  try:\n",
        "      existing_log_data = []\n",
        "      with open(log_file_path, 'r') as file:\n",
        "          reader = csv.DictReader(file)\n",
        "          for row in reader:\n",
        "              existing_log_data.append(row)\n",
        "  except Exception as e:\n",
        "      print(f\"Error loading log data: {e}\")\n",
        "      existing_log_data = []\n",
        "else:\n",
        "  # If the file doesn't exist, create an empty list for the log data\n",
        "  existing_log_data = []\n",
        "\n",
        "# Calculate additional evaluation metrics\n",
        "binary_predictions = (prediction_Warmup >= best_threshold).astype(int)\n",
        "y_true = Y_test_split\n",
        "conf_matrix = confusion_matrix(y_true, binary_predictions)\n",
        "sensitivity = recall_score(y_true, binary_predictions)\n",
        "specificity = recall_score(y_true, binary_predictions, pos_label=0)\n",
        "precision = precision_score(y_true, binary_predictions)\n",
        "f1 = f1_score(y_true, binary_predictions)\n",
        "accuracy = accuracy_score(y_true, binary_predictions)\n",
        "auc = roc_auc_score(y_true, prediction_Warmup)\n",
        "\n",
        "\n",
        "model_layers = [layer.name for layer in custom_vgg_model.layers]\n",
        "\n",
        "\n",
        "# Define the initial log data\n",
        "initial_log_data = {\n",
        "\n",
        "  \"Date of Run\": current_datetime,\n",
        "  \"Run By\": RUN_BY,\n",
        "#   \"Channels\": channels,\n",
        "  \"RESAMPLING\" : \"Q\"+str(RESAMPLING),\n",
        "  \"CropSize\" : Fixed_CropSize,\n",
        "  \"Resize\" : RESIZE,\n",
        "  \"SMOTE\" : SMOTE_STATE,\n",
        "  \"EPOCHS\" : EPOCHS,\n",
        "  \"BATCHSIZE\" : BATCHSIZE,\n",
        "  \"Augmentation_settings\": json.dumps(augmentation_settings),\n",
        "  \"Model_Config\": json.dumps(model_kwargs),\n",
        "  \"Model_layers\": model_layers,\n",
        "  \"Optimizer\" : [CA_Scheduler.T_max, CA_Scheduler.eta_max, CA_Scheduler.eta_min],\n",
        "  \"Loss Type\": \"binary\" if isinstance(custom_vgg_model.loss, tf.keras.losses.BinaryCrossentropy) else \"categorical\",\n",
        "  \"Optimizer Used\": str(custom_vgg_model.optimizer),\n",
        "  \"Comment\":COMMENT\n",
        "}\n",
        "\n",
        "# Add the initial log data, evaluation metrics, and date to the log data\n",
        "evaluation_metrics = {\n",
        "  \"Sensitivity\": sensitivity,\n",
        "  \"Specificity\": specificity,\n",
        "  \"Precision\": precision,\n",
        "  \"F1 Score\": f1,\n",
        "  \"Accuracy\": accuracy,\n",
        "  \"Max_Val_AUC\" : max_valAUC,\n",
        "  \"AUC\": auc,\n",
        "  \"Best Threshold\": best_threshold,\n",
        "  \"Loss_fig_path\": f\"/kaggle/working//{RUN_BY}/Figures/Loss_{current_datetime}\",\n",
        "  \"AUC_fig_path\": f\"/kaggle/working//{RUN_BY}/Figures/AUC_{current_datetime}\"\n",
        "}\n",
        "\n",
        "# Combine initial log data and evaluation metrics\n",
        "combined_log_data = {**initial_log_data, **evaluation_metrics}\n",
        "\n",
        "# Append the combined log data to the existing log data\n",
        "existing_log_data.append(combined_log_data)\n",
        "\n",
        "# Get all unique field names including keys from existing_log_data\n",
        "fieldnames = set().union(*(d.keys() for d in existing_log_data))\n",
        "\n",
        "# Save the updated log data to the CSV file in Google Drive\n",
        "# Define the desired order of columns\n",
        "desired_column_order = [\n",
        "  \"Date of Run\",\n",
        "  \"Run By\",\n",
        "#   \"Channels\",\n",
        "  \"RESAMPLING\",\n",
        "  \"CropSize\",\n",
        "  \"Resize\",\n",
        "  \"SMOTE\",\n",
        "  \"EPOCHS\",\n",
        "  \"BATCHSIZE\",\n",
        "  \"Augmentation_settings\",\n",
        "  \"Model_Config\",\n",
        "  \"Model_layers\",\n",
        "  \"Optimizer\",\n",
        "  \"Loss Type\",\n",
        "  \"Optimizer Used\",\n",
        "  \"Comment\",\n",
        "  \"Sensitivity\",\n",
        "  \"Specificity\",\n",
        "  \"Precision\",\n",
        "  \"F1 Score\",\n",
        "  \"Accuracy\",\n",
        "  \"Max_Val_AUC\",\n",
        "  \"AUC\",\n",
        "  \"Best Threshold\",\n",
        "  \"Loss_fig_path\",\n",
        "  \"AUC_fig_path\"\n",
        "]\n",
        "\n",
        "# Save the updated log data to the CSV file in Google Drive\n",
        "with open(log_file_path, 'w', newline='') as file:\n",
        "  writer = csv.DictWriter(file, fieldnames=desired_column_order)\n",
        "  writer.writeheader()\n",
        "  writer.writerows(existing_log_data)\n",
        "\n",
        "print(\"Log data saved successfully.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
